{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pzM1_ykHaFur"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from transformers import RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NLxxwd1scQNv"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCaDM5rkmsf9"
   },
   "source": [
    "# Datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1732006247385,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "mZ7lTlkyaG7u",
    "outputId": "19435ba3-6504-40b9-9dc7-86d8529e28ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "CRITICAL      2621\n",
       "CONSPIRACY    1379\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_en_train_completed.csv')\n",
    "df=df.iloc[:4000,:]\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rinAOGUjmsf-"
   },
   "source": [
    "# Datos balanceados (Aumento de Datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7GhxP1owmsf_"
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('dataset_en_train_completed.csv')\n",
    "df= df.iloc[:4000]\n",
    "\n",
    "df_augmented= pd.read_csv('dataset_en_train_completed.csv')\n",
    "df_augmented= df_augmented.iloc[4000:]\n",
    "#df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "W4K5aVHFmsgA"
   },
   "outputs": [],
   "source": [
    "original_counts = df['category'].value_counts()\n",
    "df_conspiracy = df[df['category'] == 'CONSPIRACY']\n",
    "df_conspiracy_augmented = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "critical_count = original_counts.get('CRITICAL', 0) \n",
    "conspiracy_count = original_counts.get('CONSPIRACY', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "oZNTqKKsmsgA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>annotations</th>\n",
       "      <th>spacy_tokens</th>\n",
       "      <th>matched_words</th>\n",
       "      <th>top_3_emotions</th>\n",
       "      <th>max_emotion</th>\n",
       "      <th>top_morals</th>\n",
       "      <th>max_moral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5206</td>\n",
       "      <td>this is massive australian senator malcolm rob...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>[{'span_text': 'Australian Senator Malcolm Rob...</td>\n",
       "      <td>WyJUSElTIiwgIklTIiwgIk1BU1NJVkUiLCAiQXVzdHJhbG...</td>\n",
       "      <td>['senator', 'politician', 'are', 'roberts', 'm...</td>\n",
       "      <td>['inspiration', 'amusement', 'anger']</td>\n",
       "      <td>inspiration</td>\n",
       "      <td>{'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...</td>\n",
       "      <td>no moral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387</td>\n",
       "      <td>i m deeply concerned that the push to vaccinat...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'I ’m deeply concerned that the...</td>\n",
       "      <td>WyJcdTIwMWMiLCAiSSIsICJcdTIwMTltIiwgImRlZXBseS...</td>\n",
       "      <td>['concerned', 'consequences', 'shots', 'dystop...</td>\n",
       "      <td>['inspiration', 'amusement', 'fear']</td>\n",
       "      <td>inspiration</td>\n",
       "      <td>{'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...</td>\n",
       "      <td>no moral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13116</td>\n",
       "      <td>they wanted to know your vaccination status an...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'someone who died suddenly', 'c...</td>\n",
       "      <td>WyIyMDIxIiwgIjoiLCAiVGhleSIsICJ3YW50ZWQiLCAidG...</td>\n",
       "      <td>['see', 'be', 'someone', 'nt', 'allowed', 'res...</td>\n",
       "      <td>['inspiration', 'indifference', 'amusement']</td>\n",
       "      <td>inspiration</td>\n",
       "      <td>{'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...</td>\n",
       "      <td>authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11439</td>\n",
       "      <td>anthony fauci once again defended brutal chine...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'brutal Chinese lockdowns', 'ca...</td>\n",
       "      <td>WyJBbnRob255IiwgIkZhdWNpIiwgIm9uY2UiLCAiYWdhaW...</td>\n",
       "      <td>['news', 'defends', 'forcefully', 'chinese', '...</td>\n",
       "      <td>['anger', 'annoyance', 'inspiration']</td>\n",
       "      <td>anger</td>\n",
       "      <td>{'harm': 2.33333333333, 'cheating': 0.0, 'betr...</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>proof has emerged showing that death from wuha...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'death from Wuhan coronavirus (...</td>\n",
       "      <td>WyJQcm9vZiIsICJoYXMiLCAiZW1lcmdlZCIsICJzaG93aW...</td>\n",
       "      <td>['death', 'alive', 'due', 'infinite', 'breakin...</td>\n",
       "      <td>['inspiration', 'amusement', 'fear']</td>\n",
       "      <td>inspiration</td>\n",
       "      <td>{'harm': 2.1666666666666696, 'cheating': 0.0, ...</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>E0S3P</td>\n",
       "      <td>. zickute . com video ubxufaftemjq uk police c...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['death', 'in', 'country', 'org', 'stop', 'dam...</td>\n",
       "      <td>['inspiration', 'amusement', 'anger']</td>\n",
       "      <td>inspiration</td>\n",
       "      <td>{'harm': 3.0, 'cheating': 0.0, 'betrayal': 4.5...</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>ffdyY</td>\n",
       "      <td>get a claim in for medical battery. nbcnews. c...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['death', 'in', 'claim', 'science', 'vast', 'o...</td>\n",
       "      <td>['inspiration', 'amusement', 'anger']</td>\n",
       "      <td>inspiration</td>\n",
       "      <td>{'harm': 0.0, 'cheating': 0.0, 'loyalty': 8.0,...</td>\n",
       "      <td>loyalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>BJ3ns</td>\n",
       "      <td>We warn against ... vaccine mandates health pa...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['system', 'abolition', 'climate', 'digital', ...</td>\n",
       "      <td>['inspiration', 'amusement', 'fear']</td>\n",
       "      <td>inspiration</td>\n",
       "      <td>{'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...</td>\n",
       "      <td>degradation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>qFOON</td>\n",
       "      <td>Vaccination center in leaks Crime against huma...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['crimes', 'leaks', 'humanity', 'medical', 'in...</td>\n",
       "      <td>['anger', 'annoyance', 'inspiration']</td>\n",
       "      <td>anger</td>\n",
       "      <td>{'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...</td>\n",
       "      <td>no moral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>h9Gzo</td>\n",
       "      <td>Premier League footballers had fake vaccine pa...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['facilitate', 'rejected', 'fired', 'pass', 'i...</td>\n",
       "      <td>['anger', 'annoyance', 'indifference']</td>\n",
       "      <td>anger</td>\n",
       "      <td>{'harm': 0.0, 'cheating': 0.0, 'betrayal': 3.7...</td>\n",
       "      <td>betrayal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5242 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text    category  \\\n",
       "0      5206  this is massive australian senator malcolm rob...  CONSPIRACY   \n",
       "1      1387  i m deeply concerned that the push to vaccinat...    CRITICAL   \n",
       "2     13116  they wanted to know your vaccination status an...    CRITICAL   \n",
       "3     11439  anthony fauci once again defended brutal chine...    CRITICAL   \n",
       "4        98  proof has emerged showing that death from wuha...    CRITICAL   \n",
       "...     ...                                                ...         ...   \n",
       "5237  E0S3P  . zickute . com video ubxufaftemjq uk police c...  CONSPIRACY   \n",
       "5238  ffdyY  get a claim in for medical battery. nbcnews. c...  CONSPIRACY   \n",
       "5239  BJ3ns  We warn against ... vaccine mandates health pa...  CONSPIRACY   \n",
       "5240  qFOON  Vaccination center in leaks Crime against huma...  CONSPIRACY   \n",
       "5241  h9Gzo  Premier League footballers had fake vaccine pa...  CONSPIRACY   \n",
       "\n",
       "                                            annotations  \\\n",
       "0     [{'span_text': 'Australian Senator Malcolm Rob...   \n",
       "1     [{'span_text': 'I ’m deeply concerned that the...   \n",
       "2     [{'span_text': 'someone who died suddenly', 'c...   \n",
       "3     [{'span_text': 'brutal Chinese lockdowns', 'ca...   \n",
       "4     [{'span_text': 'death from Wuhan coronavirus (...   \n",
       "...                                                 ...   \n",
       "5237                                                NaN   \n",
       "5238                                                NaN   \n",
       "5239                                                NaN   \n",
       "5240                                                NaN   \n",
       "5241                                                NaN   \n",
       "\n",
       "                                           spacy_tokens  \\\n",
       "0     WyJUSElTIiwgIklTIiwgIk1BU1NJVkUiLCAiQXVzdHJhbG...   \n",
       "1     WyJcdTIwMWMiLCAiSSIsICJcdTIwMTltIiwgImRlZXBseS...   \n",
       "2     WyIyMDIxIiwgIjoiLCAiVGhleSIsICJ3YW50ZWQiLCAidG...   \n",
       "3     WyJBbnRob255IiwgIkZhdWNpIiwgIm9uY2UiLCAiYWdhaW...   \n",
       "4     WyJQcm9vZiIsICJoYXMiLCAiZW1lcmdlZCIsICJzaG93aW...   \n",
       "...                                                 ...   \n",
       "5237                                                NaN   \n",
       "5238                                                NaN   \n",
       "5239                                                NaN   \n",
       "5240                                                NaN   \n",
       "5241                                                NaN   \n",
       "\n",
       "                                          matched_words  \\\n",
       "0     ['senator', 'politician', 'are', 'roberts', 'm...   \n",
       "1     ['concerned', 'consequences', 'shots', 'dystop...   \n",
       "2     ['see', 'be', 'someone', 'nt', 'allowed', 'res...   \n",
       "3     ['news', 'defends', 'forcefully', 'chinese', '...   \n",
       "4     ['death', 'alive', 'due', 'infinite', 'breakin...   \n",
       "...                                                 ...   \n",
       "5237  ['death', 'in', 'country', 'org', 'stop', 'dam...   \n",
       "5238  ['death', 'in', 'claim', 'science', 'vast', 'o...   \n",
       "5239  ['system', 'abolition', 'climate', 'digital', ...   \n",
       "5240  ['crimes', 'leaks', 'humanity', 'medical', 'in...   \n",
       "5241  ['facilitate', 'rejected', 'fired', 'pass', 'i...   \n",
       "\n",
       "                                    top_3_emotions  max_emotion  \\\n",
       "0            ['inspiration', 'amusement', 'anger']  inspiration   \n",
       "1             ['inspiration', 'amusement', 'fear']  inspiration   \n",
       "2     ['inspiration', 'indifference', 'amusement']  inspiration   \n",
       "3            ['anger', 'annoyance', 'inspiration']        anger   \n",
       "4             ['inspiration', 'amusement', 'fear']  inspiration   \n",
       "...                                            ...          ...   \n",
       "5237         ['inspiration', 'amusement', 'anger']  inspiration   \n",
       "5238         ['inspiration', 'amusement', 'anger']  inspiration   \n",
       "5239          ['inspiration', 'amusement', 'fear']  inspiration   \n",
       "5240         ['anger', 'annoyance', 'inspiration']        anger   \n",
       "5241        ['anger', 'annoyance', 'indifference']        anger   \n",
       "\n",
       "                                             top_morals    max_moral  \n",
       "0     {'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...     no moral  \n",
       "1     {'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...     no moral  \n",
       "2     {'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...    authority  \n",
       "3     {'harm': 2.33333333333, 'cheating': 0.0, 'betr...         harm  \n",
       "4     {'harm': 2.1666666666666696, 'cheating': 0.0, ...         harm  \n",
       "...                                                 ...          ...  \n",
       "5237  {'harm': 3.0, 'cheating': 0.0, 'betrayal': 4.5...         harm  \n",
       "5238  {'harm': 0.0, 'cheating': 0.0, 'loyalty': 8.0,...      loyalty  \n",
       "5239  {'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...  degradation  \n",
       "5240  {'harm': 0.0, 'cheating': 0.0, 'betrayal': 0.0...     no moral  \n",
       "5241  {'harm': 0.0, 'cheating': 0.0, 'betrayal': 3.7...     betrayal  \n",
       "\n",
       "[5242 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conspiracy = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "\n",
    "# Seleccionar 1242 filas aleatorias para balancear el dataset \n",
    "df_conspiracy_sampled = df_conspiracy.sample(n=1242, random_state=42)\n",
    "df_combined = pd.concat([df, df_conspiracy_sampled])\n",
    "\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "df=df_combined.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B39VMmbEmsgC"
   },
   "source": [
    "# Transformar etiqueta de categórica a numérica\n",
    "\n",
    "Critical = 1\n",
    "Conspirancy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ixRQy14FmsgC",
    "outputId": "8eb05aa2-0098-4cae-96ea-c21d856e8339"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>top_3_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is massive australian senator malcolm rob...</td>\n",
       "      <td>0</td>\n",
       "      <td>['inspiration', 'amusement', 'anger']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i m deeply concerned that the push to vaccinat...</td>\n",
       "      <td>1</td>\n",
       "      <td>['inspiration', 'amusement', 'fear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they wanted to know your vaccination status an...</td>\n",
       "      <td>1</td>\n",
       "      <td>['inspiration', 'indifference', 'amusement']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthony fauci once again defended brutal chine...</td>\n",
       "      <td>1</td>\n",
       "      <td>['anger', 'annoyance', 'inspiration']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proof has emerged showing that death from wuha...</td>\n",
       "      <td>1</td>\n",
       "      <td>['inspiration', 'amusement', 'fear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>. zickute . com video ubxufaftemjq uk police c...</td>\n",
       "      <td>0</td>\n",
       "      <td>['inspiration', 'amusement', 'anger']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>get a claim in for medical battery. nbcnews. c...</td>\n",
       "      <td>0</td>\n",
       "      <td>['inspiration', 'amusement', 'anger']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>We warn against ... vaccine mandates health pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>['inspiration', 'amusement', 'fear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>Vaccination center in leaks Crime against huma...</td>\n",
       "      <td>0</td>\n",
       "      <td>['anger', 'annoyance', 'inspiration']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>Premier League footballers had fake vaccine pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>['anger', 'annoyance', 'indifference']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5242 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class  \\\n",
       "0     this is massive australian senator malcolm rob...      0   \n",
       "1     i m deeply concerned that the push to vaccinat...      1   \n",
       "2     they wanted to know your vaccination status an...      1   \n",
       "3     anthony fauci once again defended brutal chine...      1   \n",
       "4     proof has emerged showing that death from wuha...      1   \n",
       "...                                                 ...    ...   \n",
       "5237  . zickute . com video ubxufaftemjq uk police c...      0   \n",
       "5238  get a claim in for medical battery. nbcnews. c...      0   \n",
       "5239  We warn against ... vaccine mandates health pa...      0   \n",
       "5240  Vaccination center in leaks Crime against huma...      0   \n",
       "5241  Premier League footballers had fake vaccine pa...      0   \n",
       "\n",
       "                                    top_3_emotions  \n",
       "0            ['inspiration', 'amusement', 'anger']  \n",
       "1             ['inspiration', 'amusement', 'fear']  \n",
       "2     ['inspiration', 'indifference', 'amusement']  \n",
       "3            ['anger', 'annoyance', 'inspiration']  \n",
       "4             ['inspiration', 'amusement', 'fear']  \n",
       "...                                            ...  \n",
       "5237         ['inspiration', 'amusement', 'anger']  \n",
       "5238         ['inspiration', 'amusement', 'anger']  \n",
       "5239          ['inspiration', 'amusement', 'fear']  \n",
       "5240         ['anger', 'annoyance', 'inspiration']  \n",
       "5241        ['anger', 'annoyance', 'indifference']  \n",
       "\n",
       "[5242 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "\n",
    "new_df = df[['text', 'class','top_3_emotions']].copy()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqveDcmDeVrZ"
   },
   "source": [
    "# Parámetros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ikfbFlNHgi8T"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "\n",
    "        text = row['text']\n",
    "        important_emotions = row['top_3_emotions'] \n",
    "\n",
    "        # Tokenizamos el texto original\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        ids = torch.tensor(inputs['input_ids'])\n",
    "        mask = torch.tensor(inputs['attention_mask'])\n",
    "\n",
    "        # Tokenizamos las emociones\n",
    "        emotion_inputs = self.tokenizer.encode(important_emotions, add_special_tokens=True)\n",
    "        emotion_ids = torch.tensor(emotion_inputs)\n",
    "\n",
    "        targets = torch.tensor(row['class'])  \n",
    "        return {\n",
    "            'ids': ids,\n",
    "            'mask': mask,\n",
    "            'important_word_ids': emotion_ids,  \n",
    "            'targets': targets\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RoBERTaClass, self).__init__()\n",
    "        # Cargar el modelo preentrenado RoBERTa\n",
    "        self.l1 = transformers.RobertaModel.from_pretrained('roberta-base', output_attentions=True)\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=768, num_heads=8, dropout=0.3, batch_first=True)\n",
    "\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 1)  # Clasificación binaria\n",
    "\n",
    "    def forward(self, ids, mask, important_word_ids=None, important_emotions=None):\n",
    "        # Paso 1: Obtener embeddings del modelo para el texto original\n",
    "        outputs = self.l1(input_ids=ids, attention_mask=mask)\n",
    "        \n",
    "        # Los embeddings de las palabras del texto original (sin alteraciones) están en `outputs.last_hidden_state`\n",
    "        original_embeddings = outputs.last_hidden_state  # Shape: [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # Paso 2: Obtener embeddings de las palabras de las emociones (que pasarán por el modelo también)\n",
    "        if important_emotions is not None:\n",
    "            # Tokenizamos las palabras emocionales y las pasamos por el modelo RoBERTa para obtener sus embeddings\n",
    "            emotion_inputs = self.l1.encoder.embeddings(important_emotions)  # Embeddings de las palabras emocionales\n",
    "            # `important_emotions` debe ser un tensor que contiene las IDs de las palabras de emoción\n",
    "\n",
    "            # Concatenar los embeddings originales con los de las emociones\n",
    "            # Asumimos que 'important_emotions' tiene un tamaño compatible para la concatenación\n",
    "            concatenated_embeddings = torch.cat((original_embeddings, emotion_inputs), dim=1)\n",
    "\n",
    "        else:\n",
    "            # Si no se pasan las emociones, simplemente usamos los embeddings originales\n",
    "            concatenated_embeddings = original_embeddings\n",
    "\n",
    "        # Paso 3: Pasar los embeddings concatenados a través de la red\n",
    "        output_2 = self.l2(concatenated_embeddings.mean(dim=1))  # Promedio de las representaciones concatenadas\n",
    "        output = self.l3(output_2).squeeze(1)  # Clasificación binaria\n",
    "        return output\n",
    "\n",
    "\n",
    "model = RoBERTaClass().to(device)\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW9UZ-l8msgI"
   },
   "source": [
    "# Fine Tuning (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128717/1513134092.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample['important_word_ids'] = torch.tensor(sample['important_word_ids'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.7399255037307739\n",
      "Epoch: 1, Loss: 0.282997190952301\n",
      "Epoch: 2, Loss: 0.05724325031042099\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128717/1513134092.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample['important_word_ids'] = torch.tensor(sample['important_word_ids'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0495908185839653\n",
      "Epoch: 1, Loss: 0.038395702838897705\n",
      "Epoch: 2, Loss: 0.010447747074067593\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128717/1513134092.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample['important_word_ids'] = torch.tensor(sample['important_word_ids'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0061414288356900215\n",
      "Epoch: 1, Loss: 0.027896394953131676\n",
      "Epoch: 2, Loss: 0.010822286829352379\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128717/1513134092.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample['important_word_ids'] = torch.tensor(sample['important_word_ids'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.21250909566879272\n",
      "Epoch: 1, Loss: 0.00196507154032588\n",
      "Epoch: 2, Loss: 0.0027468749321997166\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128717/1513134092.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample['important_word_ids'] = torch.tensor(sample['important_word_ids'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0009135260479524732\n",
      "Epoch: 1, Loss: 0.0006676175398752093\n",
      "Epoch: 2, Loss: 0.0006014542886987329\n",
      "Cross-validation complete\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    max_important_word_ids_len = max(len(sample['important_word_ids']) for sample in batch)\n",
    "\n",
    "    for sample in batch:\n",
    "        sample_len = len(sample['important_word_ids'])\n",
    "        if sample_len < max_important_word_ids_len:\n",
    "            sample['important_word_ids'] = torch.cat([sample['important_word_ids'], \n",
    "                                                      torch.tensor([-1] * (max_important_word_ids_len - sample_len))])\n",
    "        sample['important_word_ids'] = torch.tensor(sample['important_word_ids'], dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        'ids': torch.stack([sample['ids'] for sample in batch]),\n",
    "        'mask': torch.stack([sample['mask'] for sample in batch]),\n",
    "        'important_word_ids': torch.stack([sample['important_word_ids'] for sample in batch]),\n",
    "        'targets': torch.tensor([sample['targets'] for sample in batch], dtype=torch.float)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch, model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    for _, data in enumerate(train_loader):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "        important_word_ids = data['important_word_ids'].to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids, mask, important_word_ids=important_word_ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        if _ % 5000 == 0:\n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def validation(model, data_loader, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "            important_word_ids = data['important_word_ids'].to(device)\n",
    "\n",
    "            outputs = model(ids, mask, important_word_ids=important_word_ids)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets\n",
    "\n",
    "\n",
    "# Evaluación de métricas\n",
    "def evaluate_metrics(outputs, targets):\n",
    "    # Convertir las salidas a 0 o 1 (clases predichas) basadas en el umbral 0.5\n",
    "    outputs = [1 if x > 0.5 else 0 for x in outputs]\n",
    "\n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(targets, outputs, average='binary')\n",
    "    mcc = matthews_corrcoef(targets, outputs)  # Calcular MCC\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "\n",
    "# Función de validación cruzada\n",
    "def cross_validate_model(model, dataframe, tokenizer, title, epochs=3, batch_size=16, k_folds=5, device='cuda'):\n",
    "    # KFold\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    metrics_list = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataframe, dataframe['class'])):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        train_df = dataframe.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = dataframe.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        # Crear datasets\n",
    "        train_set = CustomDataset(train_df, tokenizer, max_len=256)\n",
    "        val_set = CustomDataset(val_df, tokenizer, max_len=256)\n",
    "\n",
    "        # Crear dataloaders\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        # Inicializar el optimizador y la función de pérdida\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch, model, train_loader, optimizer, loss_fn, device)\n",
    "\n",
    "        # Validar el modelo\n",
    "        outputs, targets = validation(model, val_loader, device)\n",
    "\n",
    "        # Evaluar las métricas\n",
    "        fold_metrics = evaluate_metrics(outputs, targets)\n",
    "        metrics_list.append(fold_metrics)\n",
    "\n",
    "    # Guardar métricas en un DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.to_csv(f'metrics_{title}.csv', index=False)\n",
    "\n",
    "    print('Cross-validation complete')\n",
    "cross_validate_model(model, new_df, tokenizer, 'roberta_final',epochs=3, batch_size=TRAIN_BATCH_SIZE, k_folds=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXrZVs7VuPyU"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1730569342132,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "GUnpQCwytmRR",
    "outputId": "8a5d698a-c2dd-4f8a-ba8a-4a9e19fcd156"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elon now confirming what we ve been suspecting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keeping the pressure on the police to uphold t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe effective the greatest lie ever told . th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdc report admits . million people in the usa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how to use health to acquire totalitarian cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>john d. rockefeller wiped out natural cures to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>fact check biden white house falsely accuses d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>w onset acral hand lesions following mrna vacc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>we will fire unvaccinated workers cohen hadad ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>they are gearing up for the booster kill shot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  class\n",
       "0    elon now confirming what we ve been suspecting...      0\n",
       "1    keeping the pressure on the police to uphold t...      0\n",
       "2    safe effective the greatest lie ever told . th...      1\n",
       "3    cdc report admits . million people in the usa ...      1\n",
       "4    how to use health to acquire totalitarian cont...      0\n",
       "..                                                 ...    ...\n",
       "995  john d. rockefeller wiped out natural cures to...      0\n",
       "996  fact check biden white house falsely accuses d...      1\n",
       "997  w onset acral hand lesions following mrna vacc...      1\n",
       "998  we will fire unvaccinated workers cohen hadad ...      1\n",
       "999  they are gearing up for the booster kill shot ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"dataset_en_test_cleaned.csv\")\n",
    "test_df['class'] = test_df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "test_df = test_df[['text', 'class']].copy()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "3M7c-GJjmsgO",
    "outputId": "851823ab-4711-48f0-fb41-323eefce949e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results saved to roberta_final.json\n",
      "Test MCC = 0.8046594706827834\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    ids = inputs['input_ids'].to(device)\n",
    "    mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(ids, mask)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        prediction = 1 if probabilities[0] >= 0.5 else 0\n",
    "\n",
    "    return prediction, probabilities[0]\n",
    "\n",
    "\n",
    "def test_and_evaluate(model, tokenizer, test_df, filename=\"test_results.json\"):\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        text = row['text']\n",
    "        prediction, probability = predict(text, model, tokenizer)  \n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(probability)\n",
    "\n",
    "    test_df['predictions'] = predictions\n",
    "    test_df['probabilities'] = probabilities\n",
    "\n",
    "    mcc = matthews_corrcoef(test_df['class'], test_df['predictions'])\n",
    "    results = classification_report(\n",
    "        test_df['class'],\n",
    "        test_df['predictions'],\n",
    "        target_names=['CONSPIRANCY', 'CRITICAL'], \n",
    "        digits=5,\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    output_data = {\n",
    "        \"mcc\": mcc,\n",
    "        \"classification_report\": results\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "    print(f\"Test MCC = {mcc}\")\n",
    "\n",
    "# Example usage:\n",
    "test_and_evaluate(model, tokenizer, test_df, filename=\"roberta_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TatHpXamsgP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1MlYXhBkYvnDDxcjwBI9dcnzHDC8YhlRY",
     "timestamp": 1732006303116
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2daf145267054614a40293de36d69f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ba62a7dbd884db9a26c4e717d46ce9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42195991074a4eb78247eecbdd0bd834": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c40e2d6629054e1fae9f506aae6db45a",
       "IPY_MODEL_f0a1943bc20b427f97a4068aeb50d8d8",
       "IPY_MODEL_e2d4b0a3ba474a47b4002571bc5f7e46"
      ],
      "layout": "IPY_MODEL_84203a1a076349a3bde070cbda900601"
     }
    },
    "835049488c554ae2b05852b194b1ed9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84203a1a076349a3bde070cbda900601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad21d3465fd4801acef250dcc7dbc82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c40e2d6629054e1fae9f506aae6db45a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_835049488c554ae2b05852b194b1ed9c",
      "placeholder": "​",
      "style": "IPY_MODEL_d10a65de80304fa79b2e55e7bdc0d481",
      "value": "model.safetensors: 100%"
     }
    },
    "d10a65de80304fa79b2e55e7bdc0d481": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2d4b0a3ba474a47b4002571bc5f7e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bad21d3465fd4801acef250dcc7dbc82",
      "placeholder": "​",
      "style": "IPY_MODEL_f3b84121f23344d29477fcf5e546f9bd",
      "value": " 440M/440M [00:02&lt;00:00, 187MB/s]"
     }
    },
    "f0a1943bc20b427f97a4068aeb50d8d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ba62a7dbd884db9a26c4e717d46ce9a",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2daf145267054614a40293de36d69f80",
      "value": 440449768
     }
    },
    "f3b84121f23344d29477fcf5e546f9bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
